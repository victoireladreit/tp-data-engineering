version: '3'

services:
  elasticsearch: # https://hub.docker.com/_/elasticsearch/tags
    image: docker.elastic.co/elasticsearch/elasticsearch:8.10.2
    container_name: elasticsearch
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
    # restart: always
    environment:
      - xpack.security.enabled=false
      - discovery.type=single-node

  kibana:
    depends_on:
      - elasticsearch
    image: docker.elastic.co/kibana/kibana:8.10.2
    container_name: kibana
    volumes:
      - kibana-data:/usr/share/kibana/data
    ports:
      - "5601:5601"
    restart: always
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200

#  zoo1:
#    image: confluentinc/cp-zookeeper:7.1.3
#    hostname: zoo1
#    ports:
#      - "2181:2181"
#    environment:
#      ZOOKEEPER_CLIENT_PORT: 2181
#      ZOOKEEPER_SERVER_ID: 1
#      ZOOKEEPER_SERVERS: zoo1:2888:3888

# kafka1:
#   image: confluentinc/cp-kafka:7.1.3
#   hostname: kafka1
#   ports:
#     - "9092:9092"
#   environment:
#     KAFKA_ADVERTISED_LISTENERS: LISTENER_DOCKER_INTERNAL://kafka1:19092,LISTENER_DOCKER_EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9092
#     KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_DOCKER_INTERNAL:PLAINTEXT,LISTENER_DOCKER_EXTERNAL:PLAINTEXT
#     KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_DOCKER_INTERNAL
#     KAFKA_ZOOKEEPER_CONNECT: "zoo1:2181"
#     KAFKA_BROKER_ID: 1
#     KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
#     KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
#   depends_on:
#     - zoo1

# kafka-rest-proxy:
#   image: confluentinc/cp-kafka-rest:7.1.3
#   hostname: kafka-rest-proxy
#   ports:
#     - "8082:8082"
#   environment:
#     # KAFKA_REST_ZOOKEEPER_CONNECT: zoo1:2181
#     KAFKA_REST_LISTENERS: http://0.0.0.0:8082/
#     KAFKA_REST_SCHEMA_REGISTRY_URL: http://kafka-schema-registry:8081/
#     KAFKA_REST_HOST_NAME: kafka-rest-proxy
#     KAFKA_REST_BOOTSTRAP_SERVERS: PLAINTEXT://kafka1:19092
#   depends_on:
#     - zoo1
      - kafka1

#  kafka-connect:
#    image: confluentinc/cp-kafka-connect:7.2.1
#    hostname: kafka-connect
#    container_name: kafka-connect
#    ports:
#      - "8083:8083"
#    environment:
#      CONNECT_BOOTSTRAP_SERVERS: "kafka1:19092"
#      CONNECT_REST_PORT: 8083
#      CONNECT_GROUP_ID: compose-connect-group
#      CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
#      CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
#      CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
#      CONNECT_KEY_CONVERTER: io.confluent.connect.avro.AvroConverter
#      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: 'http://kafka-schema-registry:8081'
#      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
#      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: 'http://kafka-schema-registry:8081'
#      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
#      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
#      CONNECT_REST_ADVERTISED_HOST_NAME: "kafka-connect"
#      CONNECT_LOG4J_ROOT_LOGLEVEL: "INFO"
#      CONNECT_LOG4J_LOGGERS: "org.apache.kafka.connect.runtime.rest=WARN,org.reflections=ERROR"
#      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: "1"
#      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: "1"
#      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: "1"
#      CONNECT_PLUGIN_PATH: '/usr/share/java,/etc/kafka-connect/jars,/usr/share/confluent-hub-components'
#    volumes:
#      - ./connectors:/etc/kafka-connect/jars/
#      - ./kafka-connect-configs/:/home/appuser
#    depends_on:
#      - zoo1
#      - kafka1
#      - kafka-rest-proxy
#    command: # to install kafka connectors that does not come from out of the box
#      - bash
#      - -c
#      - |
#        confluent-hub install confluentinc/kafka-connect-elasticsearch:14.0.10
#        /etc/confluent/docker/run

volumes:
  elasticsearch-data:
    driver: local
  kibana-data:
    driver: local